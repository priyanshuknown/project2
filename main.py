import os
import sys
import asyncio
import json
import requests
import pandas as pd
import io
import re
import bs4
import ssl
from urllib.parse import urljoin
from fastapi import FastAPI, BackgroundTasks, HTTPException
from pydantic import BaseModel
from playwright.async_api import async_playwright
from openai import OpenAI

# --- WINDOWS FIX ---
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# --- SSL FIX (Crucial for CSV downloads) ---
ssl._create_default_https_context = ssl._create_unverified_context

# --- CONFIGURATION ---
# !!! PASTE YOUR GROQ KEY HERE !!!
GROQ_API_KEY = "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"

client = None
if GROQ_API_KEY and "PASTE_YOUR" not in GROQ_API_KEY:
    try:
        client = OpenAI(
            api_key=GROQ_API_KEY,
            base_url="https://api.groq.com/openai/v1"
        )
    except Exception as e:
        print(f"‚ùå Groq Setup Error: {e}")

MY_SECRET = "UNKNOWN"

app = FastAPI()

class TaskPayload(BaseModel):
    email: str
    secret: str
    url: str

def clean_json_text(text):
    return text.replace("```json", "").replace("```", "").strip()

async def get_llm_plan(prompt_text):
    if not client:
        return None
    try:
        print("ü§ñ Asking Groq (Llama 3.3)...")
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "You are a precise data extraction agent. Output valid JSON only."},
                {"role": "user", "content": prompt_text}
            ],
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        print(f"‚ùå Groq Failed: {e}")
        return None

async def solve_quiz(task_url: str, email: str, secret: str):
    print(f"\nüöÄ STARTING TASK: {task_url}")
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        try:
            # 1. Scrape
            await page.goto(task_url, timeout=60000)
            await page.wait_for_load_state("networkidle")
            await asyncio.sleep(1) 
            
            content = await page.evaluate("document.body.innerText")
            
            # Extract Links
            links = await page.evaluate("""
                Array.from(document.querySelectorAll('a')).map(a => 
                    `[LINK_TEXT: ${a.innerText}] (URL: ${a.href})`
                ).join('\\n')
            """)
            
            full_context = f"MAIN TEXT:\n{content}\n\n--- LINKS FOUND ---\n{links}"
            print(f"üìÑ Scraped Context (first 500 chars):\n{full_context[:500]}...")

            # 2. Plan (DEBUG PROMPT)
            prompt = f"""
            You are a Data Science Agent.
            CURRENT PAGE URL: {task_url}
            
            PAGE CONTENT:
            ---
            {full_context}
            ---
            
            YOUR TASKS:
            1. IDENTIFY SUBMISSION URL:
               - If relative ("/submit"), convert to absolute using `urljoin`.
            
            2. SOLVE THE QUESTION:
               - IF CSV/EXCEL:
                 - Code MUST: `df = pd.read_csv(url)`
                 - Filter: If text says "Cutoff X" or "Value > X", apply `df = df[df['value'] > X]` (Check column names first!).
                 - Answer: Print the sum/count/mean.
               - IF SCRAPING A LINK:
                 - Code MUST: `resp = requests.get(url, headers={{'User-Agent': 'Mozilla/5.0'}})`
                 - If HTML, try to extract text. If not found, print "SECRET_NOT_FOUND".
               - PRINT ONLY THE FINAL ANSWER.
            
            OUTPUT JSON:
            {{
                "submission_url": "https://...",
                "python_code": "import requests... headers={{'User-Agent': 'Mozilla/5.0'}}... df = pd.read_csv('url')... print(ans)",
                "text_answer": "answer_if_no_code_needed"
            }}
            """

            plan = await get_llm_plan(prompt)
            if not plan:
                return

            submission_url = plan.get("submission_url")
            final_answer = plan.get("text_answer")
            python_code = plan.get("python_code")

            if submission_url and not submission_url.startswith("http"):
                submission_url = urljoin(task_url, submission_url)

            # 3. Execute Code
            if python_code and python_code != "null":
                print("‚öôÔ∏è Executing Python Code...")
                old_stdout = sys.stdout
                redirected_output = io.StringIO()
                sys.stdout = redirected_output
                try:
                    exec_globals = {
                        'pd': pd, 
                        'requests': requests, 
                        'print': print, 
                        'urljoin': urljoin,
                        'task_url': task_url,
                        'email': email,
                        're': re,
                        'bs4': bs4,
                        'io': io,
                        'json': json
                    }
                    exec(python_code, exec_globals)
                    final_answer = redirected_output.getvalue().strip()
                except Exception as e:
                    # DEBUG: Print the actual error so we can see it in logs
                    error_msg = f"Error: {str(e)}"
                    print(error_msg) 
                    final_answer = error_msg
                finally:
                    sys.stdout = old_stdout
                print(f"‚úÖ Computed Answer: {final_answer}")

            # 4. Submit
            submit_payload = {
                "email": email,
                "secret": secret,
                "url": task_url,
                "answer": final_answer 
            }
            
            print(f"üì§ Submitting to {submission_url}...")
            resp = requests.post(submission_url, json=submit_payload)
            print(f"‚úÖ Status: {resp.status_code} | {resp.text}")

            # 5. RECURSIVE LOOP
            try:
                resp_json = resp.json()
                next_url = resp_json.get("url")
                if next_url:
                    if not next_url.startswith("http"):
                        next_url = urljoin(task_url, next_url)
                    print(f"üîÑ Next Question Found! Proceeding to: {next_url}")
                    await solve_quiz(next_url, email, secret)
                else:
                    print("üèÅ Quiz Complete.")
            except:
                pass

        except Exception as e:
            print(f"‚ùå Error: {e}")
        finally:
            await browser.close()

@app.post("/run-quiz")
async def run_quiz_endpoint(payload: TaskPayload, background_tasks: BackgroundTasks):
    if payload.secret != MY_SECRET:
        raise HTTPException(status_code=403, detail="Invalid Secret")
    background_tasks.add_task(solve_quiz, payload.url, payload.email, payload.secret)
    return {"message": "Task started"}
